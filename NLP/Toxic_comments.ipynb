{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Модели будем обучать с помощью алгоритмов RandomForestClassifier, LogisticRegression, CatBoostClassifier*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Подгрузим библиотку nltk для подготовки текста***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "w_tokenizer = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Подгрузим буржуйские стопвордс***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user-1-1120000000218418/work'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Приступим к очистке данных***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Пишем функцию, которая будет чистить от лишних символов***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def  clean_text(df, text_field, new_text_field_name):\n",
    "    df[new_text_field_name] = df[text_field].str.lower()\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(\n",
    "        lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", elem))   \n",
    "    # remove numbers\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \" \", elem))\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda x: ' '.join(x.split()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                             text_cleaned  \n",
       "0       explanation why the edits made under my userna...  \n",
       "1       d aww he matches this background colour i m se...  \n",
       "2       hey man i m really not trying to edit war it s...  \n",
       "3       more i can t make any real suggestions on impr...  \n",
       "4       you sir are my hero any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566  and for the second time of asking when your vi...  \n",
       "159567  you should be ashamed of yourself that is a ho...  \n",
       "159568  spitzer umm theres no actual article for prost...  \n",
       "159569  and it looks like it was actually you who put ...  \n",
       "159570  and i really don t think you understand i came...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(data, 'text', 'text_cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Проведем токенизацию и лемантизацию***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i  in w_tokenizer.tokenize(text)]\n",
    "    lem_text = \" \".join(lem_text)\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_cleaned_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  explanation why the edits made under my userna...   \n",
       "1  d aww he matches this background colour i m se...   \n",
       "2  hey man i m really not trying to edit war it s...   \n",
       "3  more i can t make any real suggestions on impr...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                             text_cleaned_lemmatized  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_cleaned_lemmatized'] = data['text_cleaned'].apply(lambda x: word_lemmatizer(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Делим данные на тренировочную и тестовые выборки в отношении 1 к 1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test =  train_test_split(data, shuffle=True, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Создадим корпус постов для тренировки и теста***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = train['text_cleaned_lemmatized'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test = test['text_cleaned_lemmatized'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Создадим счётчик, указав в нём стоп-слова. Посчитаем TF-IDF для корпуса тренировочных текстов, вызовем функцию fit_transform()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf = count_tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79785, 102291)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Посчитаем TF-IDF для корпуса тестовы текстов, вызовем функцию transform()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79786, 102291)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Метрикой измерения успеха обучения выберем f1, при достижении отметки 0.75***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Напишем функию для выбранных алгоритмов, воспользуем рандомным поиском, для подборки оптимальных гиперпараметров***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_model_random(model):\n",
    "    f1 = 0\n",
    "    best = 0\n",
    "    grid = 0\n",
    "    \n",
    "    #________________________________________________________________________________________\n",
    "    if model in \"LogisticRegression\":\n",
    "        grid = {\n",
    "        \"C\":[1.0,5.0, 10.0], \n",
    "        #\"class_weight\":[True, False],\n",
    "        #\"dual\":[False],\n",
    "        #\"fit_intercept\":[True, False],\n",
    "        #\"intercept_scaling\":[1],\n",
    "        #\"l1_ratio\":[None], \n",
    "        'max_iter':[int(x) for x in np.linspace(start = 1000, stop = 5500, num = 5)],\n",
    "        #'multi_class':['auto'],\n",
    "        #'n_jobs':[None],\n",
    "        #'penalty':['l2'],\n",
    "        'random_state':[12345], \n",
    "        #'solver':['lbfgs','sag'], \n",
    "        #'tol':[0.0001], \n",
    "        'verbose':[0],     \n",
    "        #'warm_start':[True, False]  \n",
    "    }\n",
    "    \n",
    "        logreg=LogisticRegression();\n",
    "        logreg_cv=RandomizedSearchCV(estimator = logreg,param_distributions = grid,scoring = 'f1',\n",
    "                                     n_iter = 5,cv =3, verbose=0, random_state=12345, n_jobs=-1);\n",
    "        logreg_cv.fit(tf_idf, train['toxic']);\n",
    "        best = logreg_cv.best_params_        \n",
    "    \n",
    "        logreg=LogisticRegression(**best)\n",
    "        logreg.fit(tf_idf, train['toxic'])\n",
    "        predicted_test = logreg.predict(tf_idf_test)\n",
    "        f1=f1_score(test.toxic, predicted_test)\n",
    "        print(\"LogisticRegression f1_test:\",f1)\n",
    " #__________________________________________   \n",
    "    if model in \"RandomForestClassifier\":\n",
    "        grid = {\n",
    "            'n_estimators':[int(x) for x in np.linspace(start = 10, stop = 110, num = 5)],\n",
    "            #'criterion':['gini'],\n",
    "            #'max_depth':[None],\n",
    "            'min_samples_split':[2, 4],\n",
    "            'min_samples_leaf':[1, 2],\n",
    "            #'min_weight_fraction_leaf':[0.0],\n",
    "            #'max_features':['auto'],\n",
    "            #'max_leaf_nodes':[None],\n",
    "            #'min_impurity_decrease':[0.0],\n",
    "            #'min_impurity_split':[None],\n",
    "            #'bootstrap':[True],\n",
    "            #'oob_score':[False],\n",
    "            #'n_jobs':[None],\n",
    "            'random_state':[None],\n",
    "            'verbose':[0],\n",
    "            #'warm_start':[False],\n",
    "            #'class_weight':[None],\n",
    "            #'ccp_alpha':[0.0],\n",
    "            #'max_samples':[None],\n",
    "        }\n",
    "    \n",
    "        ranforclas=RandomForestClassifier();\n",
    "        ranforclas_cv=RandomizedSearchCV(estimator = ranforclas,param_distributions = grid,scoring = 'f1',\n",
    "                                     n_iter = 5,cv =3, verbose=0, random_state=12345, n_jobs=-1);\n",
    "        ranforclas_cv.fit(tf_idf, train['toxic']);\n",
    "        best = ranforclas_cv.best_params_        \n",
    "    \n",
    "        ranforclas=RandomForestClassifier(**best)\n",
    "        ranforclas.fit(tf_idf, train['toxic'])\n",
    "        predicted_test = ranforclas.predict(tf_idf_test)\n",
    "        f1=f1_score(test.toxic, predicted_test)\n",
    "        print(\"RandomForestClassifier f1_test:\",f1)\n",
    " #__________________________________________   \n",
    "    if model in \"CatBoostClassifier\":\n",
    "        grid = {\n",
    "            #'early_stopping_rounds':[10],\n",
    "            'iterations':[int(x) for x in np.linspace(start = 50, stop = 100, num = 2)],\n",
    "            'learning_rate':[float(x) for x in np.linspace(start = 0.1, stop = 1, num =2)],\n",
    "            'depth':[int(x) for x in np.linspace(start = 2, stop = 16, num = 2)]}\n",
    "        \n",
    "        cbc= CatBoostClassifier() # классификатор\n",
    "        cbc_cv=RandomizedSearchCV(estimator = cbc,param_distributions = grid,scoring = 'f1',\n",
    "                                  n_iter = 1,cv =3, verbose=0, random_state=12345);\n",
    "        cbc_cv.fit(tf_idf, train['toxic']); # обучение классификатора\n",
    "        best = cbc_cv.best_params_  \n",
    "        \n",
    "        cbc=CatBoostClassifier(**best)\n",
    "        cbc.fit(tf_idf, train['toxic'])\n",
    "        predicted_test = cbc.predict(tf_idf_test)\n",
    "        f1=f1_score(test.toxic, predicted_test)\n",
    "        print(\"CatBoostClassifier f1_test:\",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Обучим модель алгоритмом CatBoostClassifier***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Обучим модель алгоритмом LogisticRegression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "f1_model_random('LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Обучим модель алгоритмом RandomForestClassifier***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Были загружены бибилиотки для обучения и подготовки данных\n",
    "2. Проведена лемантизация, токенезация и чистка текстов\n",
    "3. Созданы корпуса на обучающей и тесвовой выборках\n",
    "4. Посчитаны TF-IDF\n",
    "5. Обучены три алгоритма с поиском лучших гиперпараметров на рандомном поиске и выбрана лучшая модель LogisticRegression с наибольшим показателем F1 = 0.764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Выводы выводов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Меньшей проблемой было очистить данные и подготовить корпуса.\n",
    "2. Самая частая проблема мертвый kernel при расчете модели, только когда считал на локальной машине это удалось преодолеть. Время расчетов слишком большое, попытки прикрутить расчет через GPU для CatBoost не увенчались успехом.\n",
    "3. Об использовании BERT даже не приходится мечтать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
